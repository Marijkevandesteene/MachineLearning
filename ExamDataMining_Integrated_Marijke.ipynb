{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Machine Learning with Python\n",
    "\n",
    "Submitted by : \n",
    "\n",
    "Dries Luts (dries-luts@hotmail.com)<br />\n",
    "Bino Maiheu (binomaiheu@gmail.com)<br />\n",
    "Marijke Van De Steene (marijkevandesteene@hotmail.com)<br />\n",
    "\n",
    "This notebook is submitted by the group above for the course exame \"Machine Learning with Python\", taught by Bart Van Rompaye. Course IPVW-\n",
    "ICES 2024, **due date**: 2024-07-03 23:59. \n",
    "\n",
    "# Changelog\n",
    "\n",
    "- **2024-06-05** [MV] : Initial version\n",
    "- **2024-06-06** [BM] : Consolidated structure, imported initial analysis from notebooks \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Importing packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import scipy.stats as stats\n",
    "import scikitplot as skplt \n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler  # for preprocessing & scaling\n",
    "from sklearn.preprocessing import PolynomialFeatures  # for polynomial features preprocessing\n",
    "from sklearn.impute import SimpleImputer, KNNImputer   # for missing values imputation\n",
    "from sklearn.model_selection import train_test_split  # train-test splits\n",
    "from sklearn.model_selection import StratifiedKFold  # K-fold resampling, stratified\n",
    "from sklearn.model_selection import GridSearchCV  # Hyperparameter tuning\n",
    "from sklearn.calibration import CalibratedClassifierCV  # Hyperparameter tuning with calibration\n",
    "from sklearn.calibration import calibration_curve  # calibration curve plotting\n",
    "from sklearn.calibration import CalibrationDisplay  # calibration curve plotting\n",
    "from sklearn.metrics import confusion_matrix  # performance metrics, confusion matrix\n",
    "from sklearn.metrics import classification_report  # performance matrix classifiaction report\n",
    "from sklearn.metrics import roc_auc_score  # Area Under Receiver Operating Characteristics\n",
    "from sklearn.metrics import roc_curve  # ROC\n",
    "from sklearn.metrics import RocCurveDisplay  # ROC plotting\n",
    "from sklearn.metrics import accuracy_score  # performance metric accuracy (0/1) score\n",
    "from sklearn.metrics import precision_score  # performance metric\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression modelling\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest for classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # GBM for classification\n",
    "from sklearn.svm import SVC  # SVM for classification\n",
    "from sklearn.utils import resample  # Resampling\n",
    "from imblearn.over_sampling import SMOTE  # Synthetic upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Setting plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Jupyter magic command to show plots inline immediately\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Setting seed\n",
    "seed = 43\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Loading the house price dataset\n",
    "data_file_path = Path('input')  # Set to the path of folder where you can find 'train_V2.csv' and 'score.csv'\n",
    "\n",
    "train_filename = data_file_path / 'train_V2.csv'\n",
    "score_filename = data_file_path / 'score.csv'\n",
    "dict_filename = data_file_path / 'dictionary.csv'\n",
    "\n",
    "# -- Training data\n",
    "train_V2 = pd.read_csv(train_filename)\n",
    "score = pd.read_csv(score_filename)\n",
    "dictionary = pd.read_csv(dict_filename, sep=';')\n",
    "\n",
    "# -- Some feedback \n",
    "print('Training set shape: {}' .format(train_V2.shape))\n",
    "print('Score set shape: {}' .format(score.shape))\n",
    "print('Dictionary set shape: {}' .format(dictionary.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_V2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first analyse some high level stuff regarding the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- print list of features\n",
    "print('Training set features : ')\n",
    "print(train_V2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compare the feaures in the training & score sets\n",
    "print(\"Features in the training set but not in the scoring set (target variables) : \")\n",
    "set(train_V2.columns).difference(set(score.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Adding an index to the \n",
    "train_V2.insert(0, 'Id', range(0, 0 + len(train_V2)))\n",
    "if 'Id' in train_V2.columns:\n",
    "    train_V2 = train_V2.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Print some info\n",
    "train_V2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "\n",
    "Ok, now that we have our data loaded, lets dive into the anlysis.  In this section we shall check for consistency, handle missing values, outliers etc... We first start  with extracting categorical and numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of categorical and numerical features\n",
    "\n",
    "It's not clear immediately what the categorical and numerical features are in the dataset, this is important for later on (e.g. imputation of missing values), so we spend a little time analysing this. \n",
    "\n",
    "\n",
    "Here we aim to get a list of feature names (i.e. column names) one with categorical features, one with numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : insert code from Dries with analysis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: in the end we want 2 lists, one with the name of categorial features, the numerical features and the target features\n",
    "categorical_features = []\n",
    "numerical_features = []\n",
    "target_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset consistency tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature types\n",
    "\n",
    "Some observations in the output of `train_V2.info()` above here: \n",
    "\n",
    "- all the variables seem to be numeric (encoded as float64), except for:\n",
    "- `gender` : object contains 'M' or 'V', we will replace those with 0 and 1 for consistency with the other variables\n",
    "- `married_cd` : appears to be a boolean, so clearly this is categorical\n",
    "\n",
    "Let's first look at the feature types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- re-assign the gender to 0 or 1 \n",
    "train_V2['gender'] = train_V2['gender'].map({'M': 0, 'V': 1}) # M = 0, V = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram analysis of the score variables\n",
    "\n",
    "When looking a bit more closely to the distribution of the score variables, we noticed that score5_neg did not conform to the rest of the data. In the introductory document to the exam, it was stated that these score variables represented quantiles. Likely in case of hotel 5, this is still a raw score which has not been converted to a quantile yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(20,6))\n",
    "for k in range(5):     \n",
    "    train_V2[f\"score{k+1}_pos\"].hist(ax=axs[0][k])\n",
    "    train_V2[f\"score{k+1}_neg\"].hist(ax=axs[1][k])\n",
    "\n",
    "    axs[0][k].set_title(f\"score{k+1}_pos\")\n",
    "    axs[1][k].set_title(f\"score{k+1}_neg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's in case of hotel5 convert this score to a quantile value. To do this, we calculate the percentile rank for the score. An alternative would be to get the quantiles from the empirical cumulative distribution function, or rescale the distribution to zero mean and unit variance, assume it's shape to be - let's say - Gaussian and compute the quantiles from that cdf. But let's keep things simple : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_V2[\"score5_neg_uniform\"]  = train_V2[\"score5_neg\"].rank(method='max', pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- a small check\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,12))\n",
    "train_V2[\"score5_neg\"].hist(ax=axs[0][0])\n",
    "train_V2[\"score5_neg_uniform\"].hist(ax=axs[0][1])\n",
    "\n",
    "axs[1][0].plot(train_V2[\"score5_neg\"], train_V2[\"score5_pos\"], '.')\n",
    "axs[1][1].plot(train_V2[\"score5_neg_uniform\"], train_V2[\"score5_pos\"], '.')\n",
    "\n",
    "axs[0][0].set_title(\"score5_neg histogram\")\n",
    "axs[0][1].set_title(\"score5_neg_uniform histogram\")\n",
    "axs[1][0].set_title(\"score5_neg vs score5_pos\")\n",
    "axs[1][1].set_title(\"score5_neg_uniform vs score5_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -- and now replace the variable in the dataset\n",
    "train_V2['score5_neg'] = train_V2['score5_neg_uniform']\n",
    "train_V2.drop(columns=['score5_neg_uniform'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- make a small plot to check the resutls:\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20,6))\n",
    "for k in range(5):     \n",
    "    train_V2[f\"score{k+1}_pos\"].hist(ax=axs[0][k])\n",
    "    train_V2[f\"score{k+1}_neg\"].hist(ax=axs[1][k])\n",
    "\n",
    "    axs[0][k].set_title(f\"score{k+1}_pos\")\n",
    "    axs[1][k].set_title(f\"score{k+1}_neg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still appears a bit strange that the `score5_neg`variable is now so uniform afer converstion to a percentile rank in comparison to the other scores, but let's leave it at that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment of equal features\n",
    "\n",
    "It seemed strange that there is a variable called `tenure`, once expressed in months, once in years. So lets look a bit closer to the relation between `tenure_mts` and `tenure_yrs` via a scatterplot below : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- make a scatterplot \n",
    "sns.scatterplot(data=train_V2, x='tenure_mts', y='tenure_yrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, both express the same variable, once expressed in years, once in months. This becomes even more explicit when plotting `12*tenure_yrs`versus `tenure_mts` so it probably makes no sense to include both, let's keep `tenure_mts` and drop the `tenure_yrs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_V2.drop(columns=['tenure_yrs'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling of  missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology and TODO's \n",
    "\n",
    "1. Getting missing values descending per feature\n",
    "2. Verwerken van de scores\n",
    "3. Find instances with missing observations (% of missing for a lot of features is equal > it appears these values for these featues are missing for the same instances)\n",
    "\n",
    "**TODO**\n",
    "\n",
    "- [] beter staven waarom we effectief dan nog 53 wegsmijten\n",
    "- [] de scores uitmiddelen, maar een categorische variabele invoeren die aangeeft van welk hotel afkomstig --> zie: https://github.com/Marijkevandesteene/MachineLearning/issues/8\n",
    "- [] KNNImputer gebruiken, maar wel features herschalen hiervoor\n",
    "- [] evt. ook es die IterativeImputer gebruiken (is multivariaat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an idea about total missing values\n",
    "total_missings = train_V2.isnull().sum().sort_values(ascending=False)  # total missng values, sorted\n",
    "print(\"Top 20 of most missing features : \")\n",
    "total_missings.head(40)  # Show top 20 most missing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_missings.plot(kind='bar', figsize=(16,4), title=\"Number of missing values per feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an idea about percentage missing values\n",
    "pct_missings = train_V2.isnull().mean().sort_values(ascending=False)  # average (%) missng values, sorted\n",
    "#pct_missings.head(20)  # Show top 20 most missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_vars = [ f\"score{i+1}_{xx}\" for i in range(5) for xx in (\"pos\", \"neg\") ]\n",
    "other_vars = list(set(train_V2.columns).difference(score_vars))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16,6), gridspec_kw={'width_ratios': [1, 4]})\n",
    "\n",
    "pct_missings[score_vars].plot(kind='bar', ax=axs[0])\n",
    "pct_missings[other_vars].plot(kind='bar', ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some conclusions\n",
    "- no missing values inthe outcomes\n",
    "- a lot of missings in the scores\n",
    "- tenure_mts does have almost 10% missing --> perhaps we should not just drop it, but re-use the years !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of the score values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_V2[\"score_pos\"] = train_V2[[\"score1_pos\", \"score2_pos\", \"score3_pos\", \"score4_pos\", \"score5_pos\"]].mean(axis=1)\n",
    "train_V2[\"score_neg\"] = train_V2[[\"score1_neg\", \"score2_neg\", \"score3_neg\", \"score4_neg\", \"score5_neg\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
    "train_V2[\"score_neg\"].hist(ax=axs[0])\n",
    "train_V2[\"score_pos\"].hist(ax=axs[1])\n",
    "axs[0].set_title(\"score_neg\")\n",
    "axs[1].set_title(\"score_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the features missing mor than 35% (score*_pos, neg)\n",
    "print(f\"Shape of train_V2 BEFORE dropping missing features: {train_V2.shape}\")\n",
    "missing_a_lot = pct_missings[pct_missings > 0.35].index  # we take from all variables those missing most, and take the row-idx\n",
    "print(f\"Columns missing more than 15% :{missing_a_lot}\")\n",
    "train_V2 = train_V2.drop(missing_a_lot, axis=1)\n",
    "print(f\"Shape of train_V2 AFTER dropping missing features: {train_V2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a number of instances (53) data seems to be missing for a list of features. These will be eliminated from the dataset\n",
    "#missing_data.to_csv('missing_data.csv')\n",
    "instances_missingsData = train_V2[train_V2.loc[:,['company_ic','claims_no','income_am','gold_status','nights_booked','gender','shop_am','retired','fam_adult_size','children_no','divorce','profit_last_am','sport_ic','crd_lim_rec','credit_use_ic','gluten_ic','lactose_ic','insurance_ic','prev_all_in_stay','profit_am','bar_no','age','marketing_permit','urban_ic']].isnull().sum(axis=1) == 24]\n",
    "print(instances_missingsData.index)\n",
    "train_V2 = train_V2.drop(instances_missingsData.index)\n",
    "\n",
    "# drop the rows, we already dropped 10 columns, so be careful here... , better way to code this up\n",
    "#drop_rows = train_V2[train_V2.isnull().sum(axis=1) > 30 ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = train_V2.isnull().sum().sort_values(ascending=False)\n",
    "print(\"These are the features for which we still have missing values : \")\n",
    "missing_rows[missing_rows>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### knn-imputer voor missing scores: add_indicator:\n",
    "\n",
    "What is the add_indicator parameter in the imputers?\n",
    "In addition to imputing the missing values, the imputers have an add_indicator parameter that marks the values that were missing, which might carry some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_feats = missing_rows[missing_rows>0].index.to_list()\n",
    "print(\"Feature with missing values : \")\n",
    "print(missing_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_V2.loc[:,['score_pos','score_neg']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_feats_categorical = ['presidential', 'dining_ic', 'shop_use']\n",
    "missing_feats_continuous = ['tenure_mts', 'neighbor_income', 'cab_requests','score_pos','score_neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the missing features, with SimpleImputer we have to select between continuous & categorical features\n",
    "# probably here as well, for now we're just using the uniform weights, but check afterwards if the categorical\n",
    "# values are ok\n",
    "imputer_knn = KNNImputer(n_neighbors=5, weights='uniform').set_output(transform=\"pandas\")\n",
    "\n",
    "train_V2 = imputer_knn.fit_transform(X=train_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total amount of missings\n",
    "total_total_missings = train_V2.isnull().sum().sum()\n",
    "print(f'Are there any missings at all anymore, if this is zero, there are none: {total_total_missings}')\n",
    "# YAY!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly and outlier detection\n",
    "\n",
    "\n",
    "Hoeven niet noodzakelijk dingen eruit te zwieren, maar wel minstens aangeven dat we er naar gekeken hebben en argumenteren waarom er niets uit gaat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can not handle missing values\n",
    "# Fitting default isolation forest for anomaly/outlier detection\n",
    "# Importing the correct class as usual\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Checking which hyperparameters are available\n",
    "# print(f\"Hyperparamerters for IsolationForest class: {IsolationForest().get_params()}\")\n",
    "\n",
    "# Initializing model\n",
    "if_model = IsolationForest(n_estimators=100, random_state=seed)\n",
    "\n",
    "# Fitting (only X data, because unsupervised)\n",
    "if_model.fit(X=train_V2)\n",
    "\n",
    "# Predicting on the same data\n",
    "y_pred_train = if_model.predict(X=train_V2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations and exploratory analysis\n",
    "\n",
    "Now that we have reasonably clean data, let's perform some initial exploratory analysis, correlation plots, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The outcome to maximize is profit - damage\n",
    "\n",
    "# don't assign to dataframe just yet ???\n",
    "train_V2['revenue'] = train_V2['outcome_profit'] - train_V2['outcome_damage_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking univariate distribution of the revenue\n",
    "sns.displot(train_V2['revenue']);  # With seaborn for a change\n",
    "plt.xticks(rotation=45); # Rotating x labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But I guess a scatter plot would've done well also\n",
    "\n",
    "plt.scatter(x = range(0, 0 + len(train_V2)),y=train_V2['revenue'], alpha=0.5);  # alpha=0.5 makes it a bit see through\n",
    "plt.xlabel('Id');\n",
    "plt.ylabel('revenue');\n",
    "plt.title('Alternative: scatter plot');\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "x = 'neighbor_income'\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x=train_V2[x], y=train_V2['outcome_profit']);\n",
    "plt.scatter(x=train_V2[x], y=train_V2['outcome_damage_amount']);\n",
    "plt.title('profit and damage');\n",
    "plt.xlabel(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot-type for year built vs SalePrice\n",
    "plt.figure(figsize=(25, 10), dpi=500)  # Bumping up image size and DPI for better viewing\n",
    "sns.boxplot(x='divorce', y='outcome_profit', data=train_V2);\n",
    "plt.xticks(rotation=90);  # To rotate x-axis labels\n",
    "plt.title('Relationship of divorce versus profit');\n",
    "plt.show()  # remember: necessary to do this when trying to plot multiple plots from a single cell!\n",
    "\n",
    "# But I guess a scatter plot would've done well also\n",
    "plt.scatter(x=train_V2['income_am'], y=train_V2['outcome_profit'], alpha=0.5);  # alpha=0.5 makes it a bit see through\n",
    "plt.xlabel('income_am');\n",
    "plt.ylabel('outcome_profit');\n",
    "plt.title('Alternative: scatter plot of income versus profit');\n",
    "plt.show() \n",
    "\n",
    "# Correlation matrix between features\n",
    "corrmat = train_V2.corr(numeric_only=True)  # Since Pandas 2.0 you need to supply this attribute\n",
    "plt.figure(figsize=(12, 12));\n",
    "sns.heatmap(corrmat, vmax=1, square=True);\n",
    "# Note, we keep SalePrice in here as well, proceed with caution (no data snooping!)\n",
    "\n",
    "# Scatterplot matrix (might take a while)\n",
    "plot_cols = ['outcome_damage_inc', 'income_am', 'profit_last_am', 'profit_am', 'damage_am', 'damage_inc', 'crd_lim_rec']\n",
    "sns.pairplot(train_V2[plot_cols], height=2.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making train-test set split (Note: we're taking 30% test set size here instead of 20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_v2_stan_df.drop(['outcome_damage_amount','outcome_damage_inc','outcome_profit'], axis=1), # features DF\n",
    "                                                    train_v2_stan_df['revenue'],   # target DF/series\n",
    "                                                    test_size=0.3, # 30% as test or validation set (who cares about the exact names)\n",
    "                                                    shuffle=True,  # This shuffles the data! (Important)\n",
    "                                                    random_state=seed)  # setting seed for consistent results\n",
    "\n",
    "# I'll also make standardized (normalized) versions\n",
    "scaler = StandardScaler().set_output(transform='pandas')\n",
    "scaler.fit(X=X_train)\n",
    "X_train_norm = scaler.transform(X=X_train)\n",
    "X_test_norm = scaler.transform(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- trainen op log outcome profit?\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "\n",
    "Goal of the What do we need to predict? Is it available as outcome in our data\n",
    "1. the revenue per client (= profit - damage)\n",
    "    - needs to be calculated\n",
    "2. predict which clients will cause damage\n",
    "    - outcome_damage_inc\n",
    "3. predict the amount of damage fot those who will cause damage / wreak havoc\n",
    "    - outcome_damage_amount\n",
    "\n",
    "Calculate revenue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- es trainen op apart amount profit & damage, maar ook es op verschil (revenue)\n",
    "\n",
    "## verdeling\n",
    "\n",
    "- Bino : GBM\n",
    "- Marijke : RF\n",
    "- Dries : SVR/SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing / train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().set_output(transform='pandas')\n",
    "train_v2_stan_df = scaler.fit_transform(X=train_V2)\n",
    "\n",
    "#\n",
    "\n",
    "#train_v2_stan_df.drop('outcome_profit', axis=1)\n",
    "#train_v2_stan_df.drop('outcome_damage_inc', axis=1)\n",
    "#train_v2_stan_df.drop('outcome_damage_amount', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
